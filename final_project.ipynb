{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87eb3cda-b21d-4baf-82a4-5866f068d8fc",
   "metadata": {},
   "source": [
    "# Final Project for Research Computing in Earth Science\n",
    "## *Investigating Ocean Acidification in the Arctic* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38152d9-4450-4520-b4b4-443bbbc1f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pooch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce0cae-88b3-4040-9c9d-a2b826126999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf877923-9e32-4f3b-99ba-6fdc5da7049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c624c51-835c-4404-a21e-ba1796408bd6",
   "metadata": {},
   "source": [
    "https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3bd290-2746-4a0d-8d89-c75040b29eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>iso_time</th>\n",
       "      <th>nbs_mean</th>\n",
       "      <th>nbs_n</th>\n",
       "      <th>nbs_stdev</th>\n",
       "      <th>sbs_mean</th>\n",
       "      <th>sbs_n</th>\n",
       "      <th>sbs_stdev</th>\n",
       "      <th>wai_mean</th>\n",
       "      <th>wai_n</th>\n",
       "      <th>...</th>\n",
       "      <th>eai_stdev</th>\n",
       "      <th>wgoa_mean</th>\n",
       "      <th>wgoa_n</th>\n",
       "      <th>wgoa_stdev</th>\n",
       "      <th>cgoa_mean</th>\n",
       "      <th>cgoa_n</th>\n",
       "      <th>cgoa_stdev</th>\n",
       "      <th>egoa_mean</th>\n",
       "      <th>egoa_n</th>\n",
       "      <th>egoa_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s since Jan. 1, 1970</td>\n",
       "      <td>ISO_time</td>\n",
       "      <td>degree_C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>degree_C</td>\n",
       "      <td>degree_C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>degree_C</td>\n",
       "      <td>degree_C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369446400.0</td>\n",
       "      <td>1981-09-16T00:00:00Z</td>\n",
       "      <td>8.467217257015182</td>\n",
       "      <td>30434.0</td>\n",
       "      <td>1.6443871370910899</td>\n",
       "      <td>9.489801230477996</td>\n",
       "      <td>16904.0</td>\n",
       "      <td>0.8510722730586068</td>\n",
       "      <td>10.37621870653686</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118713</td>\n",
       "      <td>10.765192</td>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.623467</td>\n",
       "      <td>10.830621</td>\n",
       "      <td>27162.0</td>\n",
       "      <td>0.892712</td>\n",
       "      <td>12.412395</td>\n",
       "      <td>18886.0</td>\n",
       "      <td>0.724267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372124800.0</td>\n",
       "      <td>1981-10-17T00:00:00Z</td>\n",
       "      <td>5.9866948373002185</td>\n",
       "      <td>17394.0</td>\n",
       "      <td>1.8645184343316477</td>\n",
       "      <td>7.337625127988916</td>\n",
       "      <td>16603.0</td>\n",
       "      <td>0.9454006453457908</td>\n",
       "      <td>8.829858344400174</td>\n",
       "      <td>15813.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156208</td>\n",
       "      <td>9.015348</td>\n",
       "      <td>18487.0</td>\n",
       "      <td>0.705724</td>\n",
       "      <td>9.052213</td>\n",
       "      <td>28949.0</td>\n",
       "      <td>0.918016</td>\n",
       "      <td>10.901439</td>\n",
       "      <td>19654.0</td>\n",
       "      <td>0.815306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374716800.0</td>\n",
       "      <td>1981-11-16T00:00:00Z</td>\n",
       "      <td>1.498189865947222</td>\n",
       "      <td>23722.0</td>\n",
       "      <td>1.5981986433698805</td>\n",
       "      <td>5.083241002970228</td>\n",
       "      <td>14477.0</td>\n",
       "      <td>0.8158987267692981</td>\n",
       "      <td>6.7207156071308445</td>\n",
       "      <td>11892.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986623</td>\n",
       "      <td>6.285578</td>\n",
       "      <td>11047.0</td>\n",
       "      <td>0.921133</td>\n",
       "      <td>6.495266</td>\n",
       "      <td>19420.0</td>\n",
       "      <td>0.850763</td>\n",
       "      <td>8.253141</td>\n",
       "      <td>14129.0</td>\n",
       "      <td>1.297237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377395200.0</td>\n",
       "      <td>1981-12-17T00:00:00Z</td>\n",
       "      <td>1.1511721224920803</td>\n",
       "      <td>21781.0</td>\n",
       "      <td>1.509464899675726</td>\n",
       "      <td>3.497003568697427</td>\n",
       "      <td>15692.0</td>\n",
       "      <td>1.197103759879197</td>\n",
       "      <td>4.772910131020484</td>\n",
       "      <td>10838.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605709</td>\n",
       "      <td>5.019428</td>\n",
       "      <td>12164.0</td>\n",
       "      <td>0.580044</td>\n",
       "      <td>5.074895</td>\n",
       "      <td>29763.0</td>\n",
       "      <td>0.710710</td>\n",
       "      <td>6.956377</td>\n",
       "      <td>20955.0</td>\n",
       "      <td>1.019854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time              iso_time            nbs_mean    nbs_n  \\\n",
       "0  s since Jan. 1, 1970              ISO_time            degree_C      NaN   \n",
       "1           369446400.0  1981-09-16T00:00:00Z   8.467217257015182  30434.0   \n",
       "2           372124800.0  1981-10-17T00:00:00Z  5.9866948373002185  17394.0   \n",
       "3           374716800.0  1981-11-16T00:00:00Z   1.498189865947222  23722.0   \n",
       "4           377395200.0  1981-12-17T00:00:00Z  1.1511721224920803  21781.0   \n",
       "\n",
       "            nbs_stdev           sbs_mean    sbs_n           sbs_stdev  \\\n",
       "0            degree_C           degree_C      NaN            degree_C   \n",
       "1  1.6443871370910899  9.489801230477996  16904.0  0.8510722730586068   \n",
       "2  1.8645184343316477  7.337625127988916  16603.0  0.9454006453457908   \n",
       "3  1.5981986433698805  5.083241002970228  14477.0  0.8158987267692981   \n",
       "4   1.509464899675726  3.497003568697427  15692.0   1.197103759879197   \n",
       "\n",
       "             wai_mean    wai_n  ... eai_stdev  wgoa_mean   wgoa_n wgoa_stdev  \\\n",
       "0            degree_C      NaN  ...       NaN        NaN      NaN        NaN   \n",
       "1   10.37621870653686  17256.0  ...  1.118713  10.765192  17379.0   0.623467   \n",
       "2   8.829858344400174  15813.0  ...  1.156208   9.015348  18487.0   0.705724   \n",
       "3  6.7207156071308445  11892.0  ...  0.986623   6.285578  11047.0   0.921133   \n",
       "4   4.772910131020484  10838.0  ...  0.605709   5.019428  12164.0   0.580044   \n",
       "\n",
       "   cgoa_mean   cgoa_n  cgoa_stdev  egoa_mean   egoa_n  egoa_stdev  \n",
       "0        NaN      NaN         NaN        NaN      NaN         NaN  \n",
       "1  10.830621  27162.0    0.892712  12.412395  18886.0    0.724267  \n",
       "2   9.052213  28949.0    0.918016  10.901439  19654.0    0.815306  \n",
       "3   6.495266  19420.0    0.850763   8.253141  14129.0    1.297237  \n",
       "4   5.074895  29763.0    0.710710   6.956377  20955.0    1.019854  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nc\n",
    "\n",
    "url_test = 'https://polarwatch.noaa.gov/erddap/files/afsc_sst/sst.csv'\n",
    "df = pd.read_csv(url_test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf847c2-caf2-4cda-9736-caef89da2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea Ice Concentration, NOAA/NSIDC Climate Data Record V3, Arctic, 25km, Science Quality, 1978-2019, Monthly DEPRECATED\n",
    "url_ice = 'https://polarwatch.noaa.gov/erddap/files/nsidcCDRiceSQnhmday/'\n",
    "# use open_mfdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf0dd9-9920-49c1-b48c-16a32b7959dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bbfa4dc-757d-4eb6-ae83-ba8df6b3911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\n",
      "context: <!DOCTYPE^ HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"><html><head><title>404 Not Found</title></head><body><h1>Not Found</h1><p>The requested URL /data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc.dds was not found on this server.</p></body></html>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -90] NetCDF: file not found: b'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:201\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nc_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m nc \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnc_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/api.py:531\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    520\u001b[0m     decode_cf,\n\u001b[1;32m    521\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    528\u001b[0m )\n\u001b[1;32m    530\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 531\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    538\u001b[0m     backend_ds,\n\u001b[1;32m    539\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m )\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:555\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    536\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m ):\n\u001b[1;32m    554\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 555\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:384\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    378\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    379\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    382\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:332\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:393\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:387\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    388\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:189\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:207\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    205\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    206\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 207\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -90] NetCDF: file not found: b'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc'"
     ]
    }
   ],
   "source": [
    "nc_url = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc'\n",
    "nc = xr.open_dataset(nc_url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "663c1697-b70b-40e4-bb46-cebe47b61fbd",
   "metadata": {},
   "source": [
    " Column  1: DATE is ISO Date representing the month midpoint (axis TMNTH)\n",
    " Column  2: LAT is Latitude (axis YLAT)\n",
    " Column  3: LON is Longitude (axis XLON)\n",
    " Column  4: COUNT_NCRUISE is Number of cruises (count)\n",
    " Column  5: FCO2_COUNT_NOBS is Number of fco2 obs (count)\n",
    " Column  6: FCO2_AVE_WEIGHTED is fCO2 mean - per cruise weighted (uatm)\n",
    " Column  7: FCO2_AVE_UNWTD is fCO2 mean - unweighted all obs (uatm)\n",
    " Column  8: FCO2_MIN_UNWTD is fCO2 min (uatm)\n",
    " Column  9: FCO2_MAX_UNWTD is fCO2 max (uatm)\n",
    " Column 10: SST_COUNT_NOBS is Number of valid sst obs (count)\n",
    " Column 11: SST_AVE_WEIGHTED is SST mean - per cruise weighted (degrees C)\n",
    " Column 12: SST_AVE_UNWTD is SST mean - unweighted all obs (degrees C)\n",
    " Column 13: SST_MIN_UNWTD is SST min (degrees C)\n",
    " Column 14: SST_MAX_UNWTD is SST max (degrees C)\n",
    " Column 15: SALINITY_COUNT_NOBS is Number of valid salinity obs (count)\n",
    " Column 16: SALINITY_AVE_WEIGHTED is Salinity mean - per cruise weighted (PSU)\n",
    " Column 17: SALINITY_AVE_UNWTD is Salinity mean - unweighted all obs (PSU)\n",
    " Column 18: SALINITY_MIN_UNWTD is Salinity min (PSU)\n",
    " Column 19: SALINITY_MAX_UNWTD is Salinity max (PSU)\n",
    "\n",
    "Missing values are represented as -1.E+34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21b4b18c-8906-499e-b478-175ae6bdab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_complete = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea087531-8617-4b16-a1a4-25f473f77b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_url = 'https://polarwatch.noaa.gov/erddap/files/nsidcCDRice_nh_grid/seaice_conc_monthly_nh_f17_201712_v03r01.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cced11-864d-4563-b45b-b41c55a884b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax error, unexpected $end, expecting ';'\n",
      "context: Error { code=404; message=\"Not Found: File not found: seaice_conc_monthly_nh_f17_201712_v03r01.nc.dds .\";}^\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -90] NetCDF: file not found: b'https://polarwatch.noaa.gov/erddap/files/nsidcCDRice_nh_grid/seaice_conc_monthly_nh_f17_201712_v03r01.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:201\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('https://polarwatch.noaa.gov/erddap/files/nsidcCDRice_nh_grid/seaice_conc_monthly_nh_f17_201712_v03r01.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ice \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mice_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/api.py:531\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    520\u001b[0m     decode_cf,\n\u001b[1;32m    521\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    528\u001b[0m )\n\u001b[1;32m    530\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 531\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    538\u001b[0m     backend_ds,\n\u001b[1;32m    539\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m )\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:555\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    536\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m ):\n\u001b[1;32m    554\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 555\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:384\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    378\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    379\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    382\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:332\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:393\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:387\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    388\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:189\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/file_manager.py:207\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    205\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    206\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 207\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -90] NetCDF: file not found: b'https://polarwatch.noaa.gov/erddap/files/nsidcCDRice_nh_grid/seaice_conc_monthly_nh_f17_201712_v03r01.nc'"
     ]
    }
   ],
   "source": [
    "*could list out all urls of all files\n",
    "\n",
    "https://polarwatch.noaa.gov/erddap/files/nsidcCDRiceSQnhmday/\n",
    "\n",
    "ice = xr.open_dataset(ice_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59516572-6c9d-433c-9ff2-a52bfa2b1e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | NestedSequence[str | os.PathLike]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'T_Chunks'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcat_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | DataArray | Index | Sequence[str] | Sequence[DataArray] | Sequence[Index] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompatOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no_conflicts'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpreprocess\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callable[[Dataset], Dataset] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'T_Engine'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_vars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['all', 'minimal', 'different'] | list[str]\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'different'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcombine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['by_coords', 'nested']\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'by_coords'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'JoinOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattrs_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | os.PathLike | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CombineAttrsOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'override'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open multiple files as a single dataset.\n",
       "\n",
       "If combine='by_coords' then the function ``combine_by_coords`` is used to combine\n",
       "the datasets into one before returning the result, and if combine='nested' then\n",
       "``combine_nested`` is used. The filepaths must be structured according to which\n",
       "combining function is used, the details of which are given in the documentation for\n",
       "``combine_by_coords`` and ``combine_nested``. By default ``combine='by_coords'``\n",
       "will be used. Requires dask to be installed. See documentation for\n",
       "details on dask [1]_. Global attributes from the ``attrs_file`` are used\n",
       "for the combined dataset.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "paths : str or nested sequence of paths\n",
       "    Either a string glob in the form ``\"path/to/my/files/*.nc\"`` or an explicit list of\n",
       "    files to open. Paths can be given as strings or as pathlib Paths. If\n",
       "    concatenation along more than one dimension is desired, then ``paths`` must be a\n",
       "    nested list-of-lists (see ``combine_nested`` for details). (A string glob will\n",
       "    be expanded to a 1-dimensional list.)\n",
       "chunks : int, dict, 'auto' or None, optional\n",
       "    Dictionary with keys given by dimension names and values given by chunk sizes.\n",
       "    In general, these should divide the dimensions of each dataset. If int, chunk\n",
       "    each dimension by ``chunks``. By default, chunks will be chosen to load entire\n",
       "    input files into memory at once. This has a major impact on performance: please\n",
       "    see the full documentation for more details [2]_.\n",
       "concat_dim : str, DataArray, Index or a Sequence of these or None, optional\n",
       "    Dimensions to concatenate files along.  You only need to provide this argument\n",
       "    if ``combine='nested'``, and if any of the dimensions along which you want to\n",
       "    concatenate is not a dimension in the original datasets, e.g., if you want to\n",
       "    stack a collection of 2D arrays along a third dimension. Set\n",
       "    ``concat_dim=[..., None, ...]`` explicitly to disable concatenation along a\n",
       "    particular dimension. Default is None, which for a 1D list of filepaths is\n",
       "    equivalent to opening the files separately and then merging them with\n",
       "    ``xarray.merge``.\n",
       "combine : {\"by_coords\", \"nested\"}, optional\n",
       "    Whether ``xarray.combine_by_coords`` or ``xarray.combine_nested`` is used to\n",
       "    combine all the data. Default is to use ``xarray.combine_by_coords``.\n",
       "compat : {\"identical\", \"equals\", \"broadcast_equals\",               \"no_conflicts\", \"override\"}, default: \"no_conflicts\"\n",
       "    String indicating how to compare variables of the same name for\n",
       "    potential conflicts when merging:\n",
       "\n",
       "     * \"broadcast_equals\": all values must be equal when variables are\n",
       "       broadcast against each other to ensure common dimensions.\n",
       "     * \"equals\": all values and dimensions must be the same.\n",
       "     * \"identical\": all values, dimensions and attributes must be the\n",
       "       same.\n",
       "     * \"no_conflicts\": only values which are not null in both datasets\n",
       "       must be equal. The returned dataset then contains the combination\n",
       "       of all non-null values.\n",
       "     * \"override\": skip comparing and pick variable from first dataset\n",
       "\n",
       "preprocess : callable, optional\n",
       "    If provided, call this function on each dataset prior to concatenation.\n",
       "    You can find the file-name from which each dataset was loaded in\n",
       "    ``ds.encoding[\"source\"]``.\n",
       "engine : {\"netcdf4\", \"scipy\", \"pydap\", \"h5netcdf\", \"pynio\", \"cfgrib\",         \"pseudonetcdf\", \"zarr\", None}, installed backend         or subclass of xarray.backends.BackendEntrypoint, optional\n",
       "    Engine to use when reading files. If not provided, the default engine\n",
       "    is chosen based on available dependencies, with a preference for\n",
       "    \"netcdf4\".\n",
       "data_vars : {\"minimal\", \"different\", \"all\"} or list of str, default: \"all\"\n",
       "    These data variables will be concatenated together:\n",
       "      * \"minimal\": Only data variables in which the dimension already\n",
       "        appears are included.\n",
       "      * \"different\": Data variables which are not equal (ignoring\n",
       "        attributes) across all datasets are also concatenated (as well as\n",
       "        all for which dimension already appears). Beware: this option may\n",
       "        load the data payload of data variables into memory if they are not\n",
       "        already loaded.\n",
       "      * \"all\": All data variables will be concatenated.\n",
       "      * list of str: The listed data variables will be concatenated, in\n",
       "        addition to the \"minimal\" data variables.\n",
       "coords : {\"minimal\", \"different\", \"all\"} or list of str, optional\n",
       "    These coordinate variables will be concatenated together:\n",
       "     * \"minimal\": Only coordinates in which the dimension already appears\n",
       "       are included.\n",
       "     * \"different\": Coordinates which are not equal (ignoring attributes)\n",
       "       across all datasets are also concatenated (as well as all for which\n",
       "       dimension already appears). Beware: this option may load the data\n",
       "       payload of coordinate variables into memory if they are not already\n",
       "       loaded.\n",
       "     * \"all\": All coordinate variables will be concatenated, except\n",
       "       those corresponding to other dimensions.\n",
       "     * list of str: The listed coordinate variables will be concatenated,\n",
       "       in addition the \"minimal\" coordinates.\n",
       "parallel : bool, default: False\n",
       "    If True, the open and preprocess steps of this function will be\n",
       "    performed in parallel using ``dask.delayed``. Default is False.\n",
       "join : {\"outer\", \"inner\", \"left\", \"right\", \"exact\", \"override\"}, default: \"outer\"\n",
       "    String indicating how to combine differing indexes\n",
       "    (excluding concat_dim) in objects\n",
       "\n",
       "    - \"outer\": use the union of object indexes\n",
       "    - \"inner\": use the intersection of object indexes\n",
       "    - \"left\": use indexes from the first object with each dimension\n",
       "    - \"right\": use indexes from the last object with each dimension\n",
       "    - \"exact\": instead of aligning, raise `ValueError` when indexes to be\n",
       "      aligned are not equal\n",
       "    - \"override\": if indexes are of same size, rewrite indexes to be\n",
       "      those of the first object with that dimension. Indexes for the same\n",
       "      dimension must have the same size in all objects.\n",
       "attrs_file : str or path-like, optional\n",
       "    Path of the file used to read global attributes from.\n",
       "    By default global attributes are read from the first file provided,\n",
       "    with wildcard matches sorted by filename.\n",
       "combine_attrs : {\"drop\", \"identical\", \"no_conflicts\", \"drop_conflicts\",                      \"override\"} or callable, default: \"override\"\n",
       "    A callable or a string indicating how to combine attrs of the objects being\n",
       "    merged:\n",
       "\n",
       "    - \"drop\": empty attrs on returned Dataset.\n",
       "    - \"identical\": all attrs must be the same on every object.\n",
       "    - \"no_conflicts\": attrs from all objects are combined, any that have\n",
       "      the same name must also have the same value.\n",
       "    - \"drop_conflicts\": attrs from all objects are combined, any that have\n",
       "      the same name but different values are dropped.\n",
       "    - \"override\": skip comparing and copy attrs from the first dataset to\n",
       "      the result.\n",
       "\n",
       "    If a callable, it must expect a sequence of ``attrs`` dicts and a context object\n",
       "    as its only parameters.\n",
       "**kwargs : optional\n",
       "    Additional arguments passed on to :py:func:`xarray.open_dataset`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "xarray.Dataset\n",
       "\n",
       "Notes\n",
       "-----\n",
       "``open_mfdataset`` opens files with read-only access. When you modify values\n",
       "of a Dataset, even one linked to files on disk, only the in-memory copy you\n",
       "are manipulating in xarray is modified: the original file on disk is never\n",
       "touched.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "combine_by_coords\n",
       "combine_nested\n",
       "open_dataset\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       ".. [1] https://docs.xarray.dev/en/stable/dask.html\n",
       ".. [2] https://docs.xarray.dev/en/stable/dask.html#chunking-and-performance\n",
       "\u001b[0;31mFile:\u001b[0m      /srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/api.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ice = xr.open_mfdataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90738566-7bf8-4191-baa9-a951496d0e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
